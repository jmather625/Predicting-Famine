{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"./famine_data/\"\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"vgg\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 3\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 5\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'valid':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace)\n",
      "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace)\n",
      "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace)\n",
      "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): ReLU(inplace)\n",
      "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (24): ReLU(inplace)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (27): ReLU(inplace)\n",
      "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need end to be low-dimensional\n",
    "# 128 reduced error a lot from 4096\n",
    "# try maybe even 32/64 next time\n",
    "model_ft.classifier = nn.Sequential(\n",
    "    nn.Linear(in_features=25088, out_features=4096, bias=True),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(in_features=4096, out_features=256, bias=True),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(in_features=256, out_features=3, bias=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace)\n",
       "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU(inplace)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU(inplace)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): ReLU(inplace)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): ReLU(inplace)\n",
       "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=256, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'valid']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'valid']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.0.weight\n",
      "\t classifier.0.bias\n",
      "\t classifier.3.weight\n",
      "\t classifier.3.bias\n",
      "\t classifier.6.weight\n",
      "\t classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.8711 Acc: 0.6898\n",
      "valid Loss: 0.8074 Acc: 0.7214\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.7968 Acc: 0.7031\n",
      "valid Loss: 0.7186 Acc: 0.7268\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.7493 Acc: 0.7018\n",
      "valid Loss: 0.6847 Acc: 0.7295\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.7231 Acc: 0.7081\n",
      "valid Loss: 0.6684 Acc: 0.7322\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.7009 Acc: 0.7118\n",
      "valid Loss: 0.6637 Acc: 0.7174\n",
      "\n",
      "Training complete in 2m 44s\n",
      "Best val Acc: 0.732167\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_to_const = pd.read_csv('famine_data/all_ims_guide.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>im_lat</th>\n",
       "      <th>im_lon</th>\n",
       "      <th>clust_lat</th>\n",
       "      <th>clust_lon</th>\n",
       "      <th>nightlight</th>\n",
       "      <th>consumption</th>\n",
       "      <th>images</th>\n",
       "      <th>clust_num</th>\n",
       "      <th>nightlight_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-16.941666</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.9855</td>\n",
       "      <td>35.2499</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>1.951277</td>\n",
       "      <td>-16.941666_35.208332_0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-16.950000</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.9855</td>\n",
       "      <td>35.2499</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>1.951277</td>\n",
       "      <td>-16.95_35.208332_0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-16.958333</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.9855</td>\n",
       "      <td>35.2499</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>1.951277</td>\n",
       "      <td>-16.958333_35.208332_0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-16.966666</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.9855</td>\n",
       "      <td>35.2499</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>1.951277</td>\n",
       "      <td>-16.966666_35.208332_0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-16.975000</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.9855</td>\n",
       "      <td>35.2499</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>1.951277</td>\n",
       "      <td>-16.975_35.208332_0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      im_lat     im_lon  clust_lat  clust_lon  nightlight  consumption  \\\n",
       "0 -16.941666  35.208332   -16.9855    35.2499    0.036855     1.951277   \n",
       "1 -16.950000  35.208332   -16.9855    35.2499    0.036855     1.951277   \n",
       "2 -16.958333  35.208332   -16.9855    35.2499    0.036855     1.951277   \n",
       "3 -16.966666  35.208332   -16.9855    35.2499    0.036855     1.951277   \n",
       "4 -16.975000  35.208332   -16.9855    35.2499    0.036855     1.951277   \n",
       "\n",
       "                       images  clust_num  nightlight_bin  \n",
       "0  -16.941666_35.208332_0.png          0               1  \n",
       "1      -16.95_35.208332_0.png          0               1  \n",
       "2  -16.958333_35.208332_0.png          0               1  \n",
       "3  -16.966666_35.208332_0.png          0               1  \n",
       "4     -16.975_35.208332_0.png          0               1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_to_const.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './famine_data/'\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'valid']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'valid']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft.eval()   # Set model to evaluate mode\n",
    "\n",
    "running_loss = 0.0\n",
    "running_corrects = 0\n",
    "total = 0\n",
    "\n",
    "# Iterate over data.\n",
    "for inputs, labels in dataloaders_dict['train']:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # forward\n",
    "    # track history if only in train\n",
    "    with torch.set_grad_enabled(False):\n",
    "        outputs = model_ft(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    # statistics\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    total += len(preds)\n",
    "    if total == 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_corrects.double()/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def filename_to_im_tensor(file):\n",
    "    im = plt.imread(file)[:,:,:3]\n",
    "    im = (im*256).astype(np.uint8)\n",
    "    im = Image.fromarray(im)\n",
    "    im = data_transforms['train'](im)\n",
    "    return im[None].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace)\n",
       "  (2): Dropout(p=0.5)\n",
       "  (3): Linear(in_features=4096, out_features=256, bias=True)\n",
       "  (4): ReLU(inplace)\n",
       "  (5): Dropout(p=0.5)\n",
       "  (6): Linear(in_features=256, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ripped = model_ft.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace)\n",
       "  (2): Dropout(p=0.5)\n",
       "  (3): Linear(in_features=4096, out_features=256, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del ripped[6]\n",
    "del ripped[5]\n",
    "del ripped[4]\n",
    "ripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74052, 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_to_const.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = np.zeros((74052,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400, 2500, 2600, 2700, 2800, 2900, 3000, 3100, 3200, 3300, 3400, 3500, 3600, 3700, 3800, 3900, 4000, 4100, 4200, 4300, 4400, 4500, 4600, 4700, 4800, 4900, 5000, 5100, 5200, 5300, 5400, 5500, 5600, 5700, 5800, 5900, 6000, 6100, 6200, 6300, 6400, 6500, 6600, 6700, 6800, 6900, 7000, 7100, 7200, 7300, 7400, 7500, 7600, 7700, 7800, 7900, 8000, 8100, 8200, 8300, 8400, 8500, 8600, 8700, 8800, 8900, 9000, 9100, 9200, 9300, 9400, 9500, 9600, 9700, 9800, 9900, 10000, 10100, 10200, 10300, 10400, 10500, 10600, 10700, 10800, 10900, 11000, 11100, 11200, 11300, 11400, 11500, 11600, 11700, 11800, 11900, 12000, 12100, 12200, 12300, 12400, 12500, 12600, 12700, 12800, 12900, 13000, 13100, 13200, 13300, 13400, 13500, 13600, 13700, 13800, 13900, 14000, 14100, 14200, 14300, 14400, 14500, 14600, 14700, 14800, 14900, 15000, 15100, 15200, 15300, 15400, 15500, 15600, 15700, 15800, 15900, 16000, 16100, 16200, 16300, 16400, 16500, 16600, 16700, 16800, 16900, 17000, 17100, 17200, 17300, 17400, 17500, 17600, 17700, 17800, 17900, 18000, 18100, 18200, 18300, 18400, 18500, 18600, 18700, 18800, 18900, 19000, 19100, 19200, 19300, 19400, 19500, 19600, 19700, 19800, 19900, 20000, 20100, 20200, 20300, 20400, 20500, 20600, 20700, 20800, 20900, 21000, 21100, 21200, 21300, 21400, 21500, 21600, 21700, 21800, 21900, 22000, 22100, 22200, 22300, 22400, 22500, 22600, 22700, 22800, 22900, 23000, 23100, 23200, 23300, 23400, 23500, 23600, 23700, 23800, 23900, 24000, 24100, 24200, 24300, 24400, 24500, 24600, 24700, 24800, 24900, 25000, 25100, 25200, 25300, 25400, 25500, 25600, 25700, 25800, 25900, 26000, 26100, 26200, 26300, 26400, 26500, 26600, 26700, 26800, 26900, 27000, 27100, 27200, 27300, 27400, 27500, 27600, 27700, 27800, 27900, 28000, 28100, 28200, 28300, 28400, 28500, 28600, 28700, 28800, 28900, 29000, 29100, 29200, 29300, 29400, 29500, 29600, 29700, 29800, 29900, 30000, 30100, 30200, 30300, 30400, 30500, 30600, 30700, 30800, 30900, 31000, 31100, 31200, 31300, 31400, 31500, 31600, 31700, 31800, 31900, 32000, 32100, 32200, 32300, 32400, 32500, 32600, 32700, 32800, 32900, 33000, 33100, 33200, 33300, 33400, 33500, 33600, 33700, 33800, 33900, 34000, 34100, 34200, 34300, 34400, 34500, 34600, 34700, 34800, 34900, 35000, 35100, 35200, 35300, 35400, 35500, 35600, 35700, 35800, 35900, 36000, 36100, 36200, 36300, 36400, 36500, 36600, 36700, 36800, 36900, 37000, 37100, 37200, 37300, 37400, 37500, 37600, 37700, 37800, 37900, 38000, 38100, 38200, 38300, 38400, 38500, 38600, 38700, 38800, 38900, 39000, 39100, 39200, 39300, 39400, 39500, 39600, 39700, 39800, 39900, 40000, 40100, 40200, 40300, 40400, 40500, 40600, 40700, 40800, 40900, 41000, 41100, 41200, 41300, 41400, 41500, 41600, 41700, 41800, 41900, 42000, 42100, 42200, 42300, 42400, 42500, 42600, 42700, 42800, 42900, 43000, 43100, 43200, 43300, 43400, 43500, 43600, 43700, 43800, 43900, 44000, 44100, 44200, 44300, 44400, 44500, 44600, 44700, 44800, 44900, 45000, 45100, 45200, 45300, 45400, 45500, 45600, 45700, 45800, 45900, 46000, 46100, 46200, 46300, 46400, 46500, 46600, 46700, 46800, 46900, 47000, 47100, 47200, 47300, 47400, 47500, 47600, 47700, 47800, 47900, 48000, 48100, 48200, 48300, 48400, 48500, 48600, 48700, 48800, 48900, 49000, 49100, 49200, 49300, 49400, 49500, 49600, 49700, 49800, 49900, 50000, 50100, 50200, 50300, 50400, 50500, 50600, 50700, 50800, 50900, 51000, 51100, 51200, 51300, 51400, 51500, 51600, 51700, 51800, 51900, 52000, 52100, 52200, 52300, 52400, 52500, 52600, 52700, 52800, 52900, 53000, 53100, 53200, 53300, 53400, 53500, 53600, 53700, 53800, 53900, 54000, 54100, 54200, 54300, 54400, 54500, 54600, 54700, 54800, 54900, 55000, 55100, 55200, 55300, 55400, 55500, 55600, 55700, 55800, 55900, 56000, 56100, 56200, 56300, 56400, 56500, 56600, 56700, 56800, 56900, 57000, 57100, 57200, 57300, 57400, 57500, 57600, 57700, 57800, 57900, 58000, 58100, 58200, 58300, 58400, 58500, 58600, 58700, 58800, 58900, 59000, 59100, 59200, 59300, 59400, 59500, 59600, 59700, 59800, 59900, 60000, 60100, 60200, 60300, 60400, 60500, 60600, 60700, 60800, 60900, 61000, 61100, 61200, 61300, 61400, 61500, 61600, 61700, 61800, 61900, 62000, 62100, 62200, 62300, 62400, 62500, 62600, 62700, 62800, 62900, 63000, 63100, 63200, 63300, 63400, 63500, 63600, 63700, 63800, 63900, 64000, 64100, 64200, 64300, 64400, 64500, 64600, 64700, 64800, 64900, 65000, 65100, 65200, 65300, 65400, 65500, 65600, 65700, 65800, 65900, 66000, 66100, 66200, 66300, 66400, 66500, 66600, 66700, 66800, 66900, 67000, 67100, 67200, 67300, 67400, 67500, 67600, 67700, 67800, 67900, 68000, 68100, 68200, 68300, 68400, 68500, 68600, 68700, 68800, 68900, 69000, 69100, 69200, 69300, 69400, 69500, 69600, 69700, 69800, 69900, 70000, 70100, 70200, 70300, 70400, 70500, 70600, 70700, 70800, 70900, 71000, 71100, 71200, 71300, 71400, 71500, 71600, 71700, 71800, 71900, 72000, 72100, 72200, 72300, 72400, 72500, 72600, 72700, 72800, 72900, 73000, 73100, 73200, 73300, 73400, 73500, 73600, 73700, 73800, 73900, 74000, "
     ]
    }
   ],
   "source": [
    "model_ft.eval()\n",
    "for i, im_name in enumerate(im_to_const['images']):\n",
    "    image = filename_to_im_tensor('famine_data/ims_renamed/{}'.format(im_name))\n",
    "    res = np.array(model_ft(image).cpu().detach().numpy().tolist()[0])\n",
    "    feats[i,:] += res\n",
    "    if i % 100 == 0:\n",
    "        print(i, end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = np.load('forward_feats.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = os.listdir('famine_data/ims')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30477"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-14.416666000000001_34.466666.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-14.075_35.174999.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-14.233332999999998_34.408332.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13.958332999999998_33.916666.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-15.708332999999998_35.283332.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              images\n",
       "0  -14.416666000000001_34.466666.png\n",
       "1              -14.075_35.174999.png\n",
       "2  -14.233332999999998_34.408332.png\n",
       "3  -13.958332999999998_33.916666.png\n",
       "4  -15.708332999999998_35.283332.png"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_im_raw = pd.DataFrame.from_dict({'images': ims}); df_im_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>im_lat</th>\n",
       "      <th>im_lon</th>\n",
       "      <th>clust_lat</th>\n",
       "      <th>clust_lon</th>\n",
       "      <th>nightlight</th>\n",
       "      <th>consumption</th>\n",
       "      <th>images</th>\n",
       "      <th>clust_num</th>\n",
       "      <th>nightlight_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-16.941666</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.9855</td>\n",
       "      <td>35.2499</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>1.951277</td>\n",
       "      <td>-16.941666_35.208332_0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-16.950000</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.9855</td>\n",
       "      <td>35.2499</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>1.951277</td>\n",
       "      <td>-16.95_35.208332_0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-16.958333</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.9855</td>\n",
       "      <td>35.2499</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>1.951277</td>\n",
       "      <td>-16.958333_35.208332_0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-16.966666</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.9855</td>\n",
       "      <td>35.2499</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>1.951277</td>\n",
       "      <td>-16.966666_35.208332_0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-16.975000</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.9855</td>\n",
       "      <td>35.2499</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>1.951277</td>\n",
       "      <td>-16.975_35.208332_0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      im_lat     im_lon  clust_lat  clust_lon  nightlight  consumption  \\\n",
       "0 -16.941666  35.208332   -16.9855    35.2499    0.036855     1.951277   \n",
       "1 -16.950000  35.208332   -16.9855    35.2499    0.036855     1.951277   \n",
       "2 -16.958333  35.208332   -16.9855    35.2499    0.036855     1.951277   \n",
       "3 -16.966666  35.208332   -16.9855    35.2499    0.036855     1.951277   \n",
       "4 -16.975000  35.208332   -16.9855    35.2499    0.036855     1.951277   \n",
       "\n",
       "                       images  clust_num  nightlight_bin  \n",
       "0  -16.941666_35.208332_0.png          0               1  \n",
       "1      -16.95_35.208332_0.png          0               1  \n",
       "2  -16.958333_35.208332_0.png          0               1  \n",
       "3  -16.966666_35.208332_0.png          0               1  \n",
       "4     -16.975_35.208332_0.png          0               1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_to_const.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_im(x):\n",
    "    x = x.split('_')\n",
    "    return x[0] + '_' + x[1] + '.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_to_const['im_og'] = im_to_const['images'].apply(parse_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>im_lat</th>\n",
       "      <th>im_lon</th>\n",
       "      <th>clust_lat</th>\n",
       "      <th>clust_lon</th>\n",
       "      <th>nightlight</th>\n",
       "      <th>consumption</th>\n",
       "      <th>images</th>\n",
       "      <th>clust_num</th>\n",
       "      <th>nightlight_bin</th>\n",
       "      <th>im_og</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-16.941666</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.9855</td>\n",
       "      <td>35.2499</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>1.951277</td>\n",
       "      <td>-16.941666_35.208332_0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-16.941666_35.208332.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-16.950000</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.9855</td>\n",
       "      <td>35.2499</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>1.951277</td>\n",
       "      <td>-16.95_35.208332_0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-16.95_35.208332.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-16.958333</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.9855</td>\n",
       "      <td>35.2499</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>1.951277</td>\n",
       "      <td>-16.958333_35.208332_0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-16.958333_35.208332.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-16.966666</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.9855</td>\n",
       "      <td>35.2499</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>1.951277</td>\n",
       "      <td>-16.966666_35.208332_0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-16.966666_35.208332.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-16.975000</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.9855</td>\n",
       "      <td>35.2499</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>1.951277</td>\n",
       "      <td>-16.975_35.208332_0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-16.975_35.208332.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      im_lat     im_lon  clust_lat  clust_lon  nightlight  consumption  \\\n",
       "0 -16.941666  35.208332   -16.9855    35.2499    0.036855     1.951277   \n",
       "1 -16.950000  35.208332   -16.9855    35.2499    0.036855     1.951277   \n",
       "2 -16.958333  35.208332   -16.9855    35.2499    0.036855     1.951277   \n",
       "3 -16.966666  35.208332   -16.9855    35.2499    0.036855     1.951277   \n",
       "4 -16.975000  35.208332   -16.9855    35.2499    0.036855     1.951277   \n",
       "\n",
       "                       images  clust_num  nightlight_bin  \\\n",
       "0  -16.941666_35.208332_0.png          0               1   \n",
       "1      -16.95_35.208332_0.png          0               1   \n",
       "2  -16.958333_35.208332_0.png          0               1   \n",
       "3  -16.966666_35.208332_0.png          0               1   \n",
       "4     -16.975_35.208332_0.png          0               1   \n",
       "\n",
       "                      im_og  \n",
       "0  -16.941666_35.208332.png  \n",
       "1      -16.95_35.208332.png  \n",
       "2  -16.958333_35.208332.png  \n",
       "3  -16.966666_35.208332.png  \n",
       "4     -16.975_35.208332.png  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_to_const.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74052, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_to_const.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_im_raw['feat_index'] = np.arange(len(df_im_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_to_const = pd.merge(left=im_to_const, right=df_im_raw, left_on='im_og', right_on='images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74052, 12)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_to_const.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>im_lat</th>\n",
       "      <th>im_lon</th>\n",
       "      <th>clust_lat</th>\n",
       "      <th>clust_lon</th>\n",
       "      <th>nightlight</th>\n",
       "      <th>consumption</th>\n",
       "      <th>images_x</th>\n",
       "      <th>clust_num</th>\n",
       "      <th>nightlight_bin</th>\n",
       "      <th>im_og</th>\n",
       "      <th>images_y</th>\n",
       "      <th>feat_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-16.941666</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.985500</td>\n",
       "      <td>35.249900</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>1.951277</td>\n",
       "      <td>-16.941666_35.208332_0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-16.941666_35.208332.png</td>\n",
       "      <td>-16.941666_35.208332.png</td>\n",
       "      <td>6754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-16.941666</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.952974</td>\n",
       "      <td>35.203069</td>\n",
       "      <td>0.502674</td>\n",
       "      <td>2.171500</td>\n",
       "      <td>-16.941666_35.208332_1.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-16.941666_35.208332.png</td>\n",
       "      <td>-16.941666_35.208332.png</td>\n",
       "      <td>6754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-16.941666</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.934744</td>\n",
       "      <td>35.248479</td>\n",
       "      <td>0.616477</td>\n",
       "      <td>12.299129</td>\n",
       "      <td>-16.941666_35.208332_3.png</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-16.941666_35.208332.png</td>\n",
       "      <td>-16.941666_35.208332.png</td>\n",
       "      <td>6754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-16.950000</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.985500</td>\n",
       "      <td>35.249900</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>1.951277</td>\n",
       "      <td>-16.95_35.208332_0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-16.95_35.208332.png</td>\n",
       "      <td>-16.95_35.208332.png</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-16.950000</td>\n",
       "      <td>35.208332</td>\n",
       "      <td>-16.952974</td>\n",
       "      <td>35.203069</td>\n",
       "      <td>0.502674</td>\n",
       "      <td>2.171500</td>\n",
       "      <td>-16.95_35.208332_1.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-16.95_35.208332.png</td>\n",
       "      <td>-16.95_35.208332.png</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      im_lat     im_lon  clust_lat  clust_lon  nightlight  consumption  \\\n",
       "0 -16.941666  35.208332 -16.985500  35.249900    0.036855     1.951277   \n",
       "1 -16.941666  35.208332 -16.952974  35.203069    0.502674     2.171500   \n",
       "2 -16.941666  35.208332 -16.934744  35.248479    0.616477    12.299129   \n",
       "3 -16.950000  35.208332 -16.985500  35.249900    0.036855     1.951277   \n",
       "4 -16.950000  35.208332 -16.952974  35.203069    0.502674     2.171500   \n",
       "\n",
       "                     images_x  clust_num  nightlight_bin  \\\n",
       "0  -16.941666_35.208332_0.png          0               1   \n",
       "1  -16.941666_35.208332_1.png          1               1   \n",
       "2  -16.941666_35.208332_3.png          3               1   \n",
       "3      -16.95_35.208332_0.png          0               1   \n",
       "4      -16.95_35.208332_1.png          1               1   \n",
       "\n",
       "                      im_og                  images_y  feat_index  \n",
       "0  -16.941666_35.208332.png  -16.941666_35.208332.png        6754  \n",
       "1  -16.941666_35.208332.png  -16.941666_35.208332.png        6754  \n",
       "2  -16.941666_35.208332.png  -16.941666_35.208332.png        6754  \n",
       "3      -16.95_35.208332.png      -16.95_35.208332.png         298  \n",
       "4      -16.95_35.208332.png      -16.95_35.208332.png         298  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_to_const.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = im_to_const.groupby(['clust_lat', 'clust_lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "928"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_clusts = len(group); num_clusts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((num_clusts, 4096))\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, g in enumerate(group):\n",
    "    lat, long = g[0]\n",
    "    im_sub = im_to_const[(im_to_const['clust_lat'] == lat) & (im_to_const['clust_lon'] == long)].reset_index(drop=True)\n",
    "    agg_feats = np.zeros((len(im_sub), 4096))\n",
    "    for j, d in im_sub.iterrows():\n",
    "        agg_feats[j,:] = feats[d.feat_index]\n",
    "    agg_feats = agg_feats.mean(axis=0)\n",
    "    \n",
    "    x[i,:] = agg_feats\n",
    "    y.append(g[1]['consumption'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(928, 4096)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.linear_model as linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import EllipseCollection\n",
    "import seaborn as sns\n",
    "\n",
    "############################\n",
    "######### Figure 3 #########\n",
    "############################\n",
    "\n",
    "\n",
    "def predict_consumption(\n",
    "    X, y, dimension=None, k=5, k_inner=5, points=10,\n",
    "        alpha_low=1, alpha_high=5, margin=0.25):\n",
    "    \"\"\"\n",
    "    Plots predicted consumption\n",
    "    \"\"\"\n",
    "    X = reduce_dimension(X, dimension)\n",
    "    y_hat, r2 = run_cv(X, y, k, k_inner, points, alpha_low, alpha_high)\n",
    "    return X, y, y_hat, r2\n",
    "\n",
    "\n",
    "def plot_predictions(country, y, y_hat, r2, margin):\n",
    "    \"\"\"\n",
    "    Plots consumption predictions vs. true values.\n",
    "    \"\"\"\n",
    "    slope, intercept, ymin, ymax, xmin, xmax = compute_plot_params(\n",
    "        y, y_hat, margin)\n",
    "    sns.set_style('white')\n",
    "    plt.figure()\n",
    "    plt.axis('equal')\n",
    "    plt.scatter(y, y_hat, edgecolor='k', color='lightblue', s=20, marker='o')\n",
    "    x_trend = np.array([xmin, xmax]) * 1.5\n",
    "    y_trend = slope * x_trend + intercept\n",
    "    plt.plot(x_trend, y_trend, 'b-', linewidth=2,\n",
    "             color=sns.xkcd_rgb['french blue'])\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.xlabel('Log consumption expenditures', fontsize=14)\n",
    "    plt.ylabel('Model predictions', fontsize=14)\n",
    "    plt.title(country.capitalize() + ': $r^2 = {0:.2f}$'.format(r2))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compute_plot_params(y, y_hat, margin):\n",
    "    \"\"\"\n",
    "    Computes parameters for plotting consumption predictions vs. true values.\n",
    "    \"\"\"\n",
    "    slope, intercept, _, _, _ = stats.linregress(y, y_hat)\n",
    "    ymin = min(y_hat) - margin\n",
    "    ymax = max(y_hat) + margin\n",
    "    xmin = min(y) - margin\n",
    "    xmax = max(y) + margin\n",
    "    return slope, intercept, ymin, ymax, xmin, xmax\n",
    "\n",
    "############################\n",
    "######## Figure 4ab ########\n",
    "############################\n",
    "\n",
    "\n",
    "def compare_models(\n",
    "    country_path, survey, percentiles, dimension, k, k_inner, trials,\n",
    "        poverty_line, multiples):\n",
    "    \"\"\"\n",
    "    Evaluates and plots comparison of transfer learning and nightlight models.\n",
    "    \"\"\"\n",
    "    r2s, r2s_nl = evaluate_percentiles(\n",
    "        country_path, survey, percentiles, dimension, k, k_inner, trials)\n",
    "    if survey == 'lsms':\n",
    "        X, X_nl, y = load_and_reduce_country_by_percentile(\n",
    "            country_path, survey, 1.0, dimension)\n",
    "        fractions = compute_fractions(poverty_line, multiples, y)\n",
    "        plot_percentiles_lsms(percentiles, multiples, r2s, r2s_nl, fractions)\n",
    "    elif survey == 'dhs':\n",
    "        plot_percentiles_dhs(percentiles, r2s, r2s_nl)\n",
    "\n",
    "\n",
    "def load_and_reduce_country_by_percentile(\n",
    "        country_path, survey, percentile, dimension):\n",
    "    \"\"\"\n",
    "    Loads data for one country up to a certain percentile.\n",
    "    \"\"\"\n",
    "    if survey == 'lsms':\n",
    "        X, X_nl, y = load_country_lsms(country_path)\n",
    "    elif survey == 'dhs':\n",
    "        X, X_nl, y = load_country_dhs(country_path)\n",
    "    X, X_nl, y = threshold_by_percentile(X, X_nl, y, percentile)\n",
    "    X = reduce_dimension(X, dimension)\n",
    "    return X, X_nl, y\n",
    "\n",
    "\n",
    "def threshold_by_percentile(X, X_nl, y, percentile):\n",
    "    \"\"\"\n",
    "    Threshold data by output percentile.\n",
    "    \"\"\"\n",
    "    threshold = np.percentile(y, q=100*percentile)\n",
    "    X = X[y <= threshold]\n",
    "    X_nl = X_nl[y <= threshold]\n",
    "    y = y[y <= threshold]\n",
    "    return X, X_nl, y\n",
    "\n",
    "\n",
    "def evaluate_percentiles(\n",
    "        country_path, survey, percentiles, dimension, k, k_inner, trials):\n",
    "    \"\"\"\n",
    "    Evaluate transfer learning and nightlight models for each percentile.\n",
    "    \"\"\"\n",
    "    r2s = np.zeros((len(percentiles), trials))\n",
    "    r2s_nl = np.zeros((len(percentiles), trials))\n",
    "    for idx, percentile in enumerate(percentiles):\n",
    "        for trial in xrange(trials):\n",
    "            X, X_nl, y = load_and_reduce_country_by_percentile(\n",
    "                country_path, survey, percentile, dimension)\n",
    "            _, r2 = run_cv(\n",
    "                X, y, k, k_inner, points=10, alpha_low=0, alpha_high=3,\n",
    "                randomize=False)\n",
    "            r2_nl = run_cv_ols(X_nl, y, k)\n",
    "            r2s[idx, trial] = r2\n",
    "            r2s_nl[idx, trial] = r2_nl\n",
    "    r2s = r2s.mean(axis=1)\n",
    "    r2s_nl = r2s_nl.mean(axis=1)\n",
    "    return r2s, r2s_nl\n",
    "\n",
    "\n",
    "def run_cv_ols(X, y, k):\n",
    "    \"\"\"\n",
    "    Runs OLS in cross-validation to compute r-squared.\n",
    "    \"\"\"\n",
    "    r2s = np.zeros((k,))\n",
    "    kf = cross_validation.KFold(n=y.size, n_folds=k, shuffle=True)\n",
    "    fold = 0\n",
    "    for train_idx, test_idx in kf:\n",
    "        r2s, fold = evaluate_fold_ols(X, y, train_idx, test_idx, r2s, fold)\n",
    "    return r2s.mean()\n",
    "\n",
    "\n",
    "def evaluate_fold_ols(X, y, train_idx, test_idx, r2s, fold):\n",
    "    \"\"\"\n",
    "    Evaluates one fold of outer CV using OLS.\n",
    "    \"\"\"\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    X_train, X_test = scale_features(X_train, X_test)\n",
    "    y_test_hat = train_and_predict_ols(X_train, y_train, X_test)\n",
    "    r2 = stats.pearsonr(y_test, y_test_hat)[0] ** 2\n",
    "    if np.isnan(r2):\n",
    "        r2 = 0\n",
    "    r2s[fold] = r2\n",
    "    return r2s, fold + 1\n",
    "\n",
    "\n",
    "def train_and_predict_ols(X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    Trains OLS model and predicts test set.\n",
    "    \"\"\"\n",
    "    ols = linear_model.LinearRegression()\n",
    "    ols.fit(X_train, y_train)\n",
    "    y_hat = ols.predict(X_test)\n",
    "    return y_hat\n",
    "\n",
    "\n",
    "def compute_fractions(poverty_line, multiples, y):\n",
    "    \"\"\"\n",
    "    Computes the fraction of clusters below each multiple of the poverty line.\n",
    "    \"\"\"\n",
    "    fractions = np.zeros((len(multiples),))\n",
    "    for idx, multiple in enumerate(multiples):\n",
    "        fractions[idx] = (\n",
    "            np.exp(y) <= poverty_line * multiple).sum() / float(y.size)\n",
    "    return fractions\n",
    "\n",
    "\n",
    "def plot_percentiles_lsms(percentiles, multiples, r2s, r2s_nl, fractions):\n",
    "    \"\"\"\n",
    "    Plots transfer learning model vs. nightlights model at each percentile.\n",
    "    \"\"\"\n",
    "    sns.set_style('white')\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    lines = []\n",
    "    percentiles = [100 * x for x in percentiles]\n",
    "    for idx, multiple in enumerate(multiples):\n",
    "        lines.append(\n",
    "            plt.axvline(\n",
    "                100 * fractions[idx], color='r', linestyle='dashed',\n",
    "                linewidth=3.0 / (idx + 1),\n",
    "                label=str(multiple) + 'x poverty line'))\n",
    "    line_legend = plt.legend(\n",
    "        handles=lines, title='Poverty line multiples:', loc='upper right',\n",
    "        bbox_to_anchor=(0.5, 1), fontsize=10)\n",
    "    plt.gca().add_artist(line_legend)\n",
    "    curve1, = plt.plot(percentiles, r2s, label='Transfer learning')\n",
    "    curve2, = plt.plot(percentiles, r2s_nl, label='Nightlights')\n",
    "    plt.legend(\n",
    "        handles=[curve1, curve2], loc='upper right',\n",
    "        bbox_to_anchor=(0.5, 0.65))\n",
    "    plt.xlabel('Poorest percent of clusters used', fontsize=14)\n",
    "    plt.ylabel('$r^2$', fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_percentiles_dhs(percentiles, r2s, r2s_nl):\n",
    "    \"\"\"\n",
    "    Plots transfer learning model vs. nightlights model at each\n",
    "    \"\"\"\n",
    "    sns.set_style('white')\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    percentiles = [100 * x for x in percentiles]\n",
    "    plt.plot(percentiles, r2s)\n",
    "    plt.plot(percentiles, r2s_nl)\n",
    "    plt.legend(['Transfer learning', 'Nightlights'], loc='upper center')\n",
    "    plt.xlabel('Poorest percent of clusters used', fontsize=14)\n",
    "    plt.ylabel('$r^2$', fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "############################\n",
    "######## Figure 4cd ########\n",
    "############################\n",
    "\n",
    "\n",
    "def run_randomization_test(\n",
    "    country_names, country_paths, survey, dimension, k, k_inner, points,\n",
    "        alpha_low, alpha_high, trials):\n",
    "    \"\"\"\n",
    "    Runs randomization test for a set of countries.\n",
    "    \"\"\"\n",
    "    data = load_data(country_paths, survey, dimension)\n",
    "    true_r2s = compute_true_r2s(\n",
    "        data, k, k_inner, points, alpha_low, alpha_high)\n",
    "    shuffled_r2s = compute_shuffled_r2s(\n",
    "        data, k, k_inner, points, alpha_low, alpha_high, trials)\n",
    "    plot_shuffled_distributions(country_names, survey, shuffled_r2s, true_r2s)\n",
    "\n",
    "\n",
    "def compute_true_r2s(data, k, k_inner, points, alpha_low, alpha_high):\n",
    "    \"\"\"\n",
    "    Uses data to compute true model r2s.\n",
    "    \"\"\"\n",
    "    true_r2s = []\n",
    "    for (X, y) in data:\n",
    "        _, r2 = run_cv(X, y, k, k_inner, points, alpha_low, alpha_high)\n",
    "        true_r2s.append(r2)\n",
    "    return true_r2s\n",
    "\n",
    "\n",
    "def compute_shuffled_r2s(\n",
    "        data, k, k_inner, points, alpha_low, alpha_high, trials):\n",
    "    \"\"\"\n",
    "    Uses data to compute shuffled model r2s.\n",
    "    \"\"\"\n",
    "    shuffled_r2s = np.zeros((len(data), trials))\n",
    "    for data_idx, (X, y) in enumerate(data):\n",
    "        for trial in range(trials):\n",
    "            _, shuffled_r2s[data_idx, trial] = run_cv(\n",
    "                X, y, k, k_inner, points, alpha_low, alpha_high,\n",
    "                randomize=True)\n",
    "    return shuffled_r2s\n",
    "\n",
    "\n",
    "def plot_shuffled_distributions(country_names, survey, shuffled_r2s, true_r2s):\n",
    "    \"\"\"\n",
    "    Plots shuffled r2 distributions vs. true model r2s.\n",
    "    \"\"\"\n",
    "    colors = sns.color_palette('husl', len(country_names))\n",
    "    sns.set_style('white')\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    frame = plt.gca()\n",
    "    for i in xrange(len(country_names)):\n",
    "        plt.axvline(\n",
    "            true_r2s[i], color=colors[i], linestyle='dashed', linewidth=2,\n",
    "            label=country_names[i].capitalize() + ': $r^2={0:.2f}$'.format(\n",
    "                true_r2s[i]))\n",
    "    plt.legend(\n",
    "        title='True {} Models:'.format(survey.upper()), loc='lower right',\n",
    "        bbox_to_anchor=(0.6, 0.45), fontsize=12)\n",
    "    for i in xrange(len(country_names)):\n",
    "        sns.kdeplot(shuffled_r2s[i, :], shade=True, color=colors[i])\n",
    "    plt.xlim((0, max(true_r2s) + 0.05))\n",
    "    plt.xlabel('$r^2$', fontsize=18)\n",
    "    plt.ylabel('Randomized $r^2$ distribution', fontsize=14)\n",
    "    frame.yaxis.set_ticklabels([])\n",
    "    plt.show()\n",
    "\n",
    "############################\n",
    "######### Figure 5 #########\n",
    "############################\n",
    "\n",
    "\n",
    "def evaluate_models(\n",
    "    country_names, country_paths, survey, dimension, k, trials, points,\n",
    "        alpha_low, alpha_high, cmap='Greens'):\n",
    "    \"\"\"\n",
    "    Evaluates in- and out-of-country performance for models trained on set of\n",
    "    countries given.\n",
    "    \"\"\"\n",
    "    n = len(country_names)\n",
    "    performance_matrix = np.zeros((trials, n, n))\n",
    "    data = load_data(country_paths, survey, dimension=None)\n",
    "    for trial in xrange(trials):\n",
    "        for in_idx in xrange(n):\n",
    "            performance_matrix[trial, :, in_idx] = compute_column(\n",
    "                country_names[in_idx], data, in_idx, dimension, k, points,\n",
    "                alpha_low, alpha_high)\n",
    "    performance_matrix = performance_matrix.mean(axis=0)\n",
    "    plot_model_performance(performance_matrix, country_names, cmap)\n",
    "    return np.around(performance_matrix, decimals=2)\n",
    "\n",
    "\n",
    "def compute_column(\n",
    "    country_name, data, in_idx, dimension, k, points, alpha_low,\n",
    "        alpha_high):\n",
    "    \"\"\"\n",
    "    Evaluates in- and out-of-country performance for model trained on one\n",
    "    country.\n",
    "    \"\"\"\n",
    "    in_data = data[in_idx]\n",
    "    out_data = list(data)\n",
    "    out_data.pop(in_idx)\n",
    "    if country_name == 'pooled':\n",
    "        r2s_in, r2s_out = evaluate_pooled_r2s(\n",
    "            out_data, dimension, k, points, alpha_low, alpha_high)\n",
    "    else:\n",
    "        r2s_in, r2s_out = evaluate_model_r2s(\n",
    "            in_data, out_data, dimension, k, points, alpha_low, alpha_high)\n",
    "    max_idx = np.argmax(r2s_in)\n",
    "    r2s = list(r2s_out[:, max_idx])\n",
    "    r2s.insert(in_idx, r2s_in[max_idx])\n",
    "    r2s.reverse()\n",
    "    r2s = np.array(r2s)\n",
    "    return r2s\n",
    "\n",
    "\n",
    "def evaluate_pooled_r2s(all_data, dimension, k, points, alpha_low, alpha_high):\n",
    "    \"\"\"\n",
    "    Evaluates in- and out-of-country r2s for the pooled model.\n",
    "    \"\"\"\n",
    "    X_all_full, y_all = [list(data) for data in zip(*all_data)]\n",
    "    alphas = np.logspace(alpha_low, alpha_high, points)\n",
    "    r2s_in = np.zeros((k, points))\n",
    "    r2s_out = np.zeros((len(all_data), k, points))\n",
    "    kf = []\n",
    "    for i in xrange(len(X_all_full)):\n",
    "        kf.append(list(cross_validation.KFold(\n",
    "            n=all_data[i][1].size, n_folds=k, shuffle=True)))\n",
    "    for fold in xrange(k):\n",
    "        X_train, X_test, y_train, y_test = split_pooled_data(\n",
    "            kf, fold, X_all_full, y_all)\n",
    "        X_train, X_test, X_all = reduce_and_scale_features(\n",
    "            X_train, X_test, X_all_full, dimension)\n",
    "        r2s_in, r2s_out = evaluate_alphas(\n",
    "            X_train, X_test, X_all, y_train, y_test, y_all, r2s_in, r2s_out,\n",
    "            fold, alphas)\n",
    "    return r2s_in.mean(axis=0), r2s_out.mean(axis=1)\n",
    "\n",
    "\n",
    "def split_pooled_data(kf, fold, X_all_full, y_all):\n",
    "    \"\"\"\n",
    "    Splits pooled training and test data for each fold.\n",
    "    \"\"\"\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    for i in xrange(len(kf)):\n",
    "        train_ind = kf[i][fold][0]\n",
    "        test_ind = kf[i][fold][1]\n",
    "        X_train.append(X_all_full[i][train_ind])\n",
    "        X_test.append(X_all_full[i][test_ind])\n",
    "        y_train.append(y_all[i][train_ind])\n",
    "        y_test.append(y_all[i][test_ind])\n",
    "    X_train = np.vstack(X_train)\n",
    "    X_test = np.vstack(X_test)\n",
    "    y_train = np.hstack(y_train)\n",
    "    y_test = np.hstack(y_test)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def evaluate_model_r2s(\n",
    "        in_data, out_data, dimension, k, points, alpha_low, alpha_high):\n",
    "    \"\"\"\n",
    "    Evaluates in- and out-of-country r2s.\n",
    "    \"\"\"\n",
    "    X, y = in_data\n",
    "    X_out_full, y_out = [list(data) for data in zip(*out_data)]\n",
    "    alphas = np.logspace(alpha_low, alpha_high, points)\n",
    "    r2s_in = np.zeros((k, points))\n",
    "    r2s_out = np.zeros((len(out_data), k, points))\n",
    "    kf = cross_validation.KFold(n=in_data[1].size, n_folds=k, shuffle=True)\n",
    "    fold = 0\n",
    "    for train_ind, test_ind in kf:\n",
    "        X_train, X_test = X[train_ind], X[test_ind]\n",
    "        y_train, y_test = y[train_ind], y[test_ind]\n",
    "        X_train, X_test, X_out = reduce_and_scale_features(\n",
    "            X_train, X_test, X_out_full, dimension)\n",
    "        r2s_in, r2s_out = evaluate_alphas(\n",
    "            X_train, X_test, X_out, y_train, y_test, y_out, r2s_in, r2s_out,\n",
    "            fold, alphas)\n",
    "        fold += 1\n",
    "    return r2s_in.mean(axis=0), r2s_out.mean(axis=1)\n",
    "\n",
    "\n",
    "def evaluate_alphas(\n",
    "    X_train, X_test, X_out, y_train, y_test, y_out, r2s_in, r2s_out, fold,\n",
    "        alphas):\n",
    "    \"\"\"\n",
    "    Computes r2 for different regularization constants.\n",
    "    \"\"\"\n",
    "    for idx, alpha in enumerate(alphas):\n",
    "        ridge = linear_model.Ridge(alpha=alpha)\n",
    "        ridge.fit(X_train.astype(np.float), y_train.astype(np.float))\n",
    "        r2s_in[fold, idx] = compute_r2(ridge, X_test, y_test)\n",
    "        for i in xrange(len(X_out)):\n",
    "            r2s_out[i, fold, idx] = compute_r2(ridge, X_out[i], y_out[i])\n",
    "    return r2s_in, r2s_out\n",
    "\n",
    "\n",
    "def reduce_and_scale_features(X_train, X_test, X_out_full, dimension):\n",
    "    \"\"\"\n",
    "    Reduces dimension and scales in- and out-of-country features.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=dimension)\n",
    "    scaler = StandardScaler(with_mean=True, with_std=False)\n",
    "    X_train = scaler.fit_transform(pca.fit_transform(X_train))\n",
    "    X_test = scaler.transform(pca.transform(X_test))\n",
    "    X_out = []\n",
    "    for X in X_out_full:\n",
    "        X_out.append(scaler.transform(pca.transform(X)))\n",
    "    return X_train, X_test, X_out\n",
    "\n",
    "\n",
    "def compute_r2(model, X, y):\n",
    "    \"\"\"\n",
    "    Computes model r2.\n",
    "    \"\"\"\n",
    "    y_hat = model.predict(X)\n",
    "    r2 = stats.pearsonr(y, y_hat)[0] ** 2\n",
    "    return r2\n",
    "\n",
    "\n",
    "def plot_circles(data, ax, **kwargs):\n",
    "    \"\"\"\n",
    "    Plots circles for r2 values.\n",
    "    \"\"\"\n",
    "    M = np.array(data)\n",
    "    xy = np.indices(M.shape)[::-1].reshape(2, -1).T\n",
    "    w = np.abs(M).ravel()\n",
    "    h = np.abs(M).ravel()\n",
    "    a = 0\n",
    "    circles = EllipseCollection(\n",
    "        widths=w, heights=h, angles=a, units='x', offsets=xy,\n",
    "        transOffset=ax.transData, array=M.ravel(), **kwargs)\n",
    "    ax.add_collection(circles)\n",
    "    ax.set_xticks(np.arange(M.shape[1]))\n",
    "    ax.set_xticklabels(data.columns)\n",
    "    ax.set_yticks(np.arange(M.shape[0]))\n",
    "    ax.set_yticklabels(data.index, rotation=90)\n",
    "    return circles\n",
    "\n",
    "\n",
    "def plot_model_performance(data, country_names, cmap='Greens'):\n",
    "    \"\"\"\n",
    "    Makes plot for in- and out-of-country model performance.\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame(np.flipud(data))\n",
    "    data.columns = [country.capitalize() for country in country_names]\n",
    "    data.index = [country.capitalize() for country in country_names]\n",
    "    sns.set_style('white')\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    circles = plot_circles(data, ax=ax, cmap=cmap)\n",
    "    cb = fig.colorbar(circles)\n",
    "    cb.set_label('$r^2$', fontsize=16)\n",
    "    ax.margins(0.1)\n",
    "    plt.xlabel('Country trained on', fontsize=16)\n",
    "    plt.ylabel('Country evaluated on', fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "############################\n",
    "######### General ##########\n",
    "############################\n",
    "\n",
    "\n",
    "def load_data(country_paths, survey, dimension):\n",
    "    \"\"\"\n",
    "    Loads data for all surveys.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for country_path in country_paths:\n",
    "        X, y = load_and_reduce_country(country_path, survey, dimension)\n",
    "        data.append((X, y))\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_country_lsms(country_path):\n",
    "    \"\"\"\n",
    "    Loads data for one LSMS country.\n",
    "    \"\"\"\n",
    "    X = np.load(country_path + 'cluster_conv_features.npy')\n",
    "    X_nl = np.load(country_path + 'cluster_nightlights.npy').reshape(-1, 1)\n",
    "    y = np.load(country_path + 'cluster_consumptions.npy')\n",
    "    hhs = np.load(country_path + 'cluster_households.npy')\n",
    "    images = np.load(country_path + 'cluster_image_counts.npy')\n",
    "    # Filter out single households and <10 images\n",
    "    mask = np.logical_and((hhs >= 2), (images >= 10))\n",
    "    X = X[mask]\n",
    "    X_nl = X_nl[mask]\n",
    "    y = y[mask]\n",
    "    # Filter out 0 consumption clusters\n",
    "    X = X[y > 0]\n",
    "    X_nl = X_nl[y > 0]\n",
    "    y = y[y > 0]\n",
    "    y = np.log(y)\n",
    "    return X, X_nl, y\n",
    "\n",
    "\n",
    "def load_country_dhs(country_path):\n",
    "    \"\"\"\n",
    "    Loads data for one DHS country.\n",
    "    \"\"\"\n",
    "    X = np.load(country_path + 'cluster_conv_features.npy')\n",
    "    X_nl = np.load(country_path + 'cluster_nightlights.npy').reshape(-1, 1)\n",
    "    y = np.load(country_path + 'cluster_assets.npy')\n",
    "    hhs = np.load(country_path + 'cluster_households.npy')\n",
    "    images = np.load(country_path + 'cluster_image_counts.npy')\n",
    "    # Filter out single households and <10 images\n",
    "    mask = np.logical_and((hhs >= 2), (images >= 10))\n",
    "    X = X[mask]\n",
    "    X_nl = X_nl[mask]\n",
    "    y = y[mask]\n",
    "    return X, X_nl, y\n",
    "\n",
    "\n",
    "def reduce_dimension(X, dimension):\n",
    "    \"\"\"\n",
    "    Uses PCA to reduce dimensionality of features.\n",
    "    \"\"\"\n",
    "    if dimension is not None:\n",
    "        pca = PCA(n_components=dimension)\n",
    "        X = pca.fit_transform(X)\n",
    "    return X\n",
    "\n",
    "\n",
    "def load_and_reduce_country(country_path, survey, dimension):\n",
    "    \"\"\"\n",
    "    Loads data for one country and reduces the dimensionality of features.\n",
    "    \"\"\"\n",
    "    if survey == 'lsms':\n",
    "        X, _, y = load_country_lsms(country_path)\n",
    "    elif survey == 'dhs':\n",
    "        X, _, y = load_country_dhs(country_path)\n",
    "    X = reduce_dimension(X, dimension)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def run_cv(X, y, k, k_inner, points, alpha_low, alpha_high, randomize=False):\n",
    "    \"\"\"\n",
    "    Runs nested cross-validation to make predictions and compute r-squared.\n",
    "    \"\"\"\n",
    "    alphas = np.logspace(alpha_low, alpha_high, points)\n",
    "    r2s = np.zeros((k,))\n",
    "    y_hat = np.zeros_like(y)\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    fold = 0\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        r2s, y_hat, fold = evaluate_fold(\n",
    "            X, y, train_idx, test_idx, k_inner, alphas, r2s, y_hat, fold,\n",
    "            randomize)\n",
    "    return y_hat, r2s.mean()\n",
    "\n",
    "\n",
    "def scale_features(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Scales features using StandardScaler.\n",
    "    \"\"\"\n",
    "    X_scaler = StandardScaler(with_mean=True, with_std=False)\n",
    "    X_train = X_scaler.fit_transform(X_train)\n",
    "    X_test = X_scaler.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "def train_and_predict_ridge(alpha, X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    Trains ridge model and predicts test set.\n",
    "    \"\"\"\n",
    "    ridge = linear_model.Ridge(alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_hat = ridge.predict(X_test)\n",
    "    return y_hat\n",
    "\n",
    "\n",
    "def predict_inner_test_fold(X, y, y_hat, train_idx, test_idx, alpha):\n",
    "    \"\"\"\n",
    "    Predicts inner test fold.\n",
    "    \"\"\"\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    X_train, X_test = scale_features(X_train, X_test)\n",
    "    y_hat[test_idx] = train_and_predict_ridge(alpha, X_train, y_train, X_test)\n",
    "    return y_hat\n",
    "\n",
    "\n",
    "def find_best_alpha(X, y, k_inner, alphas):\n",
    "    \"\"\"\n",
    "    Finds the best alpha in an inner CV loop.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=k_inner, shuffle=True)\n",
    "    best_alpha = 0\n",
    "    best_r2 = 0\n",
    "    for idx, alpha in enumerate(alphas):\n",
    "        y_hat = np.zeros_like(y)\n",
    "        for train_idx, test_idx in kf.split(X):\n",
    "            y_hat = predict_inner_test_fold(\n",
    "                X, y, y_hat, train_idx, test_idx, alpha)\n",
    "        r2 = stats.pearsonr(y, y_hat)[0] ** 2\n",
    "        if r2 > best_r2:\n",
    "            best_alpha = alpha\n",
    "            best_r2 = r2\n",
    "    return best_alpha\n",
    "\n",
    "\n",
    "def evaluate_fold(\n",
    "    X, y, train_idx, test_idx, k_inner, alphas, r2s, y_hat, fold,\n",
    "        randomize):\n",
    "    \"\"\"\n",
    "    Evaluates one fold of outer CV.\n",
    "    \"\"\"\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    if randomize:\n",
    "        random.shuffle(y_train)\n",
    "    best_alpha = find_best_alpha(X_train, y_train, k_inner, alphas)\n",
    "    X_train, X_test = scale_features(X_train, X_test)\n",
    "    y_test_hat = train_and_predict_ridge(best_alpha, X_train, y_train, X_test)\n",
    "    r2 = stats.pearsonr(y_test, y_test_hat)[0] ** 2\n",
    "    r2s[fold] = r2\n",
    "    y_hat[test_idx] = y_test_hat\n",
    "    return r2s, y_hat, fold + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, y_hat, r2 = predict_consumption(x, y_usable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(0.7*(len(x)))\n",
    "inds = np.arange(len(x))\n",
    "train_ind = np.random.choice(inds, n_train, replace=False)\n",
    "valid_ind = np.delete(inds, train_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_usable = np.copy(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_usable[y > 20] = np.median(y[y<20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = x[train_ind]\n",
    "valid_x = x[valid_ind]\n",
    "\n",
    "train_y = y_usable[train_ind]\n",
    "valid_y = y_usable[valid_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.6574238745952328, 3.699733914307415)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.mean(), valid_y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26743656825679607"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.score(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07199772254229408"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.score(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48484020506230746"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.530520166235828e+16"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(valid_x,valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc860208dd8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(valid_y, lr.predict(valid_x), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = im_to_const.groupby(['clust_lat', 'clust_lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = groups.mean()[['nightlight', 'consumption']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idea = LinearRegression()\n",
    "n_train = int(0.8*(len(sub)))\n",
    "inds = np.arange(len(sub))\n",
    "train_ind = np.random.choice(inds, n_train, replace=False)\n",
    "valid_ind = np.delete(inds, train_ind)\n",
    "\n",
    "x = sub['nightlight'].values[train_ind].reshape(-1,1)\n",
    "x_valid = sub['nightlight'].values[valid_ind].reshape(-1,1)\n",
    "\n",
    "y_hat = sub['consumption'].values\n",
    "y_hat[y_hat>20] = np.median(y_hat[y_hat<20])\n",
    "y = y_hat[train_ind]\n",
    "y_valid = y_hat[valid_ind]\n",
    "\n",
    "idea.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idea.score(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idea.score(x_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x,y, alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

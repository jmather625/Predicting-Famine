{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["V2 of the the GCN that uses Adam instead of handmade gradient descent as well as negative-log-likelihood loss. Consider adding dropout and biases to fully match paper. Scores 79% accuracy on CORA <br>\n", "<br>\n", "In Cora, nodes are documents and edges are citation links."]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "from torch.nn.parameter import Parameter\n", "import torch.optim as optim\n", "\n", "import numpy as np\n", "import scipy.sparse as sp"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["class GCN_layer(nn.Module):\n", "    def __init__(self, in_feats, out_feats):\n", "        super(GCN_layer, self).__init__()\n", "        # I divide by in_feats to prevent the vanishing/exploding gradient problem\n", "        # not a robust/scientific solution\n", "        self.weights = Parameter(torch.randn(in_feats, out_feats).double()/in_feats)\n", "\n", "    def forward(self, adj, feats):\n", "        return adj @ feats @ self.weights"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["class GCN(nn.Module):\n", "    def __init__(self, adj_list, out_labels, nl=3, init_feats=None, train_test=0.5):\n", "        super(GCN, self).__init__()\n", "        self.adj_list = torch.from_numpy(adj_list).double()\n", "        sqrt = True # turn to False to use 'simple' adj_list normalization\n", "        D = GCN.create_D(self.adj_list, sqrt=sqrt)\n", "        if sqrt:\n", "            self.norm_adj_list = D @ self.adj_list @ D # https://tkipf.github.io/graph-convolutional-networks/#fn3\n", "        else:\n", "            self.norm_adj_list = D @ self.adj_list\n", "            \n", "        self.out_labels = torch.from_numpy(out_labels).view(-1)\n", "        self.nc = len(torch.unique(self.out_labels))\n", "        \n", "        # if no features given, use identity matrix\n", "        if init_feats is None:\n", "            init_feats = np.eye(len(adj_list))\n", "        self.init_feats = torch.from_numpy(init_feats).double()\n", "        \n", "        # can give train indices directly or give a train/test split\n", "        if type(train_test) == np.ndarray:\n", "            self.train_indices = train_test\n", "        else:\n", "            self.train_indices = np.random.choice(np.arange(len(adj_list)), int(train_test*len(adj_list)), replace=False)\n", "        \n", "        # initialize layers\n", "        self.gc1 = GCN_layer(init_feats.shape[1], 30)\n", "        self.gc2 = GCN_layer(30, self.nc)\n", "        \n", "        # optimizer\n", "        self.optimizer = optim.Adam(self.parameters(), lr=1e-2)\n", "        self.optimizer.zero_grad()\n", "        \n", "        self.epoch_stats = []\n", "        \n", "        \n", "    def create_D(adj_list, sqrt=True):\n", "        # creates the matrix for making A_hat\n", "        # sqrt is optional, can simply invert the diagonal as well, but the paper recommends this approach\n", "        D = torch.eye(len(adj_list), dtype=torch.double)\n", "        diag_sums = adj_list.sum(dim=0)\n", "        for i in range(len(adj_list)):\n", "            if sqrt:\n", "                D[i,i] = 1/torch.sqrt(diag_sums[i])\n", "            else:\n", "                D[i,i] = 1/diag_sums[i]\n", "        return D\n", "        \n", "        \n", "    def train(self, epochs=25):\n", "        for _ in range(epochs):\n", "            self.train_epoch()\n", "        \n", "        \n", "    def train_epoch(self):\n", "        \"\"\"\n", "        Propogates the model through the GCN using the formula:\n", "            L_next = A_hat @ L_cur @ w_cur\n", "            where A_hat is the normalized adj matrix\n", "        Then, backprops the model and updates the weights\n", "        Stores, the loss in self.epoch_stats\n", "        \"\"\" \n", "        out = self.gc1(self.adj_list, self.init_feats)\n", "        out = torch.relu(out)\n", "        out = self.gc2(self.adj_list, out)\n", "        out = torch.softmax(out, dim=1)\n", "                \n", "        loss = F.nll_loss(out[self.train_indices], self.out_labels[self.train_indices])\n", "        loss.backward()\n", "        \n", "        self.optimizer.step()\n", "        self.optimizer.zero_grad()\n", "        \n", "        self.epoch_stats.append(loss)\n", "        \n", "    \n", "    def predict(self):\n", "        with torch.no_grad():\n", "            out = self.gc1(self.adj_list, self.init_feats)\n", "            out = torch.relu(out)\n", "            out = self.gc2(self.adj_list, out)\n", "            out = torch.softmax(out, dim=1)\n", "            return torch.argmax(out, dim=1)"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["import networkx"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["G = networkx.karate_club_graph()"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["adj_dict = dict(G.adjacency())"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["adj_m = np.eye(len(adj_dict.keys()))\n", "for k in adj_dict:\n", "    for n in adj_dict[k]:\n", "        adj_m[k,n] = 1"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([[1., 1., 1., ..., 1., 0., 0.],\n", "       [1., 1., 1., ..., 0., 0., 0.],\n", "       [1., 1., 1., ..., 0., 1., 0.],\n", "       ...,\n", "       [1., 0., 0., ..., 1., 1., 1.],\n", "       [0., 0., 1., ..., 1., 1., 1.],\n", "       [0., 0., 0., ..., 1., 1., 1.]])"]}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": ["adj_m # this has self loops, so A is a neighbor of A; this is good"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["out_labels = []\n", "for d in G.nodes:\n", "    if G.nodes[d]['club'] == 'Mr. Hi':\n", "        out_labels.append(0)\n", "    else:\n", "        out_labels.append(1)\n", "out_labels = np.array(out_labels)"]}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n", "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"]}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": ["out_labels # 0 = Mr. Hi, 1 = the other guy"]}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [], "source": ["# giving the model about 0.3 of the data makes it predict nearly every node correctly\n", "gcn = GCN(adj_m, out_labels, nl=3, init_feats=None, train_test=0.2)"]}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"data": {"text/plain": ["tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n", "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0])"]}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": ["preds_init = gcn.predict(); preds_init # nonsense initial predictions"]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n", "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"]}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": ["out_labels"]}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"data": {"text/plain": ["0.08823529411764706"]}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}], "source": ["(preds_init.numpy() == out_labels).mean() # very bad clearly"]}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [], "source": ["gcn.train(epochs=40)"]}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [{"data": {"text/plain": ["0.9705882352941176"]}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}], "source": ["preds = gcn.predict()\n", "(preds.numpy() == out_labels).mean()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [], "source": ["def encode_onehot(labels):\n", "    classes = set(labels)\n", "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n", "                    enumerate(classes)}\n", "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n", "                             dtype=np.int32)\n", "    return labels_onehot\n", "\n", "def normalize(mx):\n", "    \"\"\"Row-normalize sparse matrix\"\"\"\n", "    rowsum = np.array(mx.sum(1))\n", "    r_inv = np.power(rowsum, -1).flatten()\n", "    r_inv[np.isinf(r_inv)] = 0.\n", "    r_mat_inv = sp.diags(r_inv)\n", "    mx = r_mat_inv.dot(mx)\n", "    return mx"]}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [], "source": ["# from https://github.com/tkipf/gcn\n", "def load_data(path=\"data/cora/\", dataset=\"cora\"):\n", "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n", "    print('Loading {} dataset...'.format(dataset))\n", "\n", "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset),\n", "                                        dtype=np.dtype(str))\n", "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n", "    labels = encode_onehot(idx_features_labels[:, -1])\n", "\n", "    # build graph\n", "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n", "    idx_map = {j: i for i, j in enumerate(idx)}\n", "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset),\n", "                                    dtype=np.int32)\n", "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n", "                     dtype=np.int32).reshape(edges_unordered.shape)\n", "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n", "                        shape=(labels.shape[0], labels.shape[0]),\n", "                        dtype=np.float32)\n", "\n", "    # build symmetric adjacency matrix\n", "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n", "\n", "    features = normalize(features)\n", "    adj = normalize(adj + sp.eye(adj.shape[0]))\n", "\n", "    idx_train = range(140)\n", "    idx_val = range(200, 500)\n", "    idx_test = range(500, 1500)\n", "    \n", "    labels = np.where(labels)[1]\n", "\n", "    return adj, features, labels, idx_train, idx_val, idx_test"]}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Loading cora dataset...\n"]}], "source": ["adj, features, labels, idx_train, idx_val, idx_test = load_data()"]}, {"cell_type": "code", "execution_count": 20, "metadata": {}, "outputs": [{"data": {"text/plain": ["(2708, 2708)"]}, "execution_count": 20, "metadata": {}, "output_type": "execute_result"}], "source": ["adj = adj.todense(); adj.shape"]}, {"cell_type": "code", "execution_count": 21, "metadata": {}, "outputs": [{"data": {"text/plain": ["matrix([[0., 0., 0., ..., 0., 0., 0.],\n", "        [0., 0., 0., ..., 0., 0., 0.],\n", "        [0., 0., 0., ..., 0., 0., 0.],\n", "        ...,\n", "        [0., 0., 0., ..., 0., 0., 0.],\n", "        [0., 0., 0., ..., 0., 0., 0.],\n", "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"]}, "execution_count": 21, "metadata": {}, "output_type": "execute_result"}], "source": ["features = features.todense(); features"]}, {"cell_type": "code", "execution_count": 22, "metadata": {"scrolled": true}, "outputs": [{"data": {"text/plain": ["array([4, 5, 6, ..., 1, 2, 4])"]}, "execution_count": 22, "metadata": {}, "output_type": "execute_result"}], "source": ["labels"]}, {"cell_type": "code", "execution_count": 23, "metadata": {}, "outputs": [{"data": {"text/plain": ["range(0, 140)"]}, "execution_count": 23, "metadata": {}, "output_type": "execute_result"}], "source": ["idx_train"]}, {"cell_type": "code", "execution_count": 24, "metadata": {}, "outputs": [{"data": {"text/plain": ["array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n", "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n", "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n", "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n", "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n", "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n", "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n", "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n", "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n", "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n", "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139])"]}, "execution_count": 24, "metadata": {}, "output_type": "execute_result"}], "source": ["known = np.array(list(idx_train)); known"]}, {"cell_type": "code", "execution_count": 25, "metadata": {}, "outputs": [], "source": ["gcn = GCN(adj, labels, init_feats=features, train_test=known)"]}, {"cell_type": "code", "execution_count": 26, "metadata": {}, "outputs": [{"data": {"text/plain": ["tensor([1, 2, 4,  ..., 4, 2, 1])"]}, "execution_count": 26, "metadata": {}, "output_type": "execute_result"}], "source": ["init_preds = gcn.predict(); init_preds"]}, {"cell_type": "code", "execution_count": 27, "metadata": {}, "outputs": [{"data": {"text/plain": ["0.1894387001477105"]}, "execution_count": 27, "metadata": {}, "output_type": "execute_result"}], "source": ["(init_preds.numpy() == labels).mean()"]}, {"cell_type": "code", "execution_count": 28, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["CPU times: user 3min 48s, sys: 2.76 s, total: 3min 51s\n", "Wall time: 21.5 s\n"]}], "source": ["%time gcn.train(150)"]}, {"cell_type": "code", "execution_count": 29, "metadata": {}, "outputs": [{"data": {"text/plain": ["0.7950516986706057"]}, "execution_count": 29, "metadata": {}, "output_type": "execute_result"}], "source": ["preds = gcn.predict()\n", "(preds.numpy() == labels).mean()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"kernelspec": {"display_name": "SPIN-famine", "language": "python", "name": "spin-famine"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 2}